{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "import nltk.data\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn import metrics, preprocessing, pipeline, model_selection, naive_bayes\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB, BernoulliNB\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "import xgboost as xgb\n",
    "\n",
    "import time\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling1D, Conv1D, MaxPooling1D, Flatten\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 200)\n",
    "train = pd.read_csv('open/new_train.csv')\n",
    "test = pd.read_csv('open/new_test.csv')\n",
    "\n",
    "Y_train = LabelEncoder().fit_transform(train['author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "X_train=train['text'].str.replace('[^a-zA-Z0-9]', ' ')\n",
    "y_train=train['author']\n",
    "X_test=test['text'].str.replace('[^a-zA-Z0-9]', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[['punc_1','punc_2','punc_3','punc_4','punc_5','punc_6','punc_7', 'index', 'text', 'author']]\n",
    "\n",
    "# test = test[['punc_1','punc_2','punc_3','punc_4','punc_5','punc_6','punc_7', 'index', 'text']]\n",
    "\n",
    "columns = ['punc_1','punc_2','punc_3','punc_4','punc_5','punc_6','punc_7',\n",
    "          'tfidf_MNB_0', 'tfidf_MNB_1', 'tfidf_MNB_2', 'tfidf_MNB_3', 'tfidf_MNB_4',\n",
    "           'tfidf_CMNB_0', 'tfidf_CMNB_1', 'tfidf_CMNB_2', 'tfidf_CMNB_3', 'tfidf_CMNB_4',\n",
    "           'tfidf_CBNB_0', 'tfidf_CBNB_1', 'tfidf_CBNB_2', 'tfidf_CBNB_3', 'tfidf_CBNB_4',\n",
    "           'tfidf_CH_0', 'tfidf_CH_1', 'tfidf_CH_2', 'tfidf_CH_3', 'tfidf_CH_4',\n",
    "           'count_MNB_0', 'count_MNB_1', 'count_MNB_2', 'count_MNB_3', 'count_MNB_4',\n",
    "           'count_CMNB_0', 'count_CMNB_1', 'count_CMNB_2', 'count_CMNB_3', 'count_CMNB_4',\n",
    "           'count_CBNB_0', 'count_CBNB_1', 'count_CBNB_2', 'count_CBNB_3', 'count_CBNB_4',\n",
    "           'count_CH_0', 'count_CH_1', 'count_CH_2', 'count_CH_3', 'count_CH_4',\n",
    "           'ff_0', 'ff_1', 'ff_2', 'ff_3', 'ff_4', \n",
    "           'nn_0', 'nn_1', 'nn_2', 'nn_3', 'nn_4'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer - word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 22:35\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   20.8s remaining:  1.0min\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   22.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.031\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.3\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   17.8s remaining:   53.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.031\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   18.8s remaining:   56.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.031\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   19.5s remaining:   58.7s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   20.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.031\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.3\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   19.6s remaining:   59.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   20.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.031\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.6029955683225479, 0.604635802543013, 0.6211772682884821, 0.6004100043878932, 0.6154952568908586]\n",
      "Mean cv score :  0.608942780086559\n",
      "2020/12/01 22:35\n",
      "2020/12/01 22:39\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_MNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                  'vect__max_df': (0.25, 0.3),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "                  'clf__alpha': [0.024, 0.031],\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_MNB_0\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_MNB_1\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_MNB_2\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_MNB_3\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_MNB_4\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_MNB_0\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_MNB_1\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_MNB_2\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_MNB_3\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_MNB_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 22:39\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.5\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.5976665473926792, 0.5975338255728783, 0.6173897988183089, 0.5963371295574684, 0.6096579691870107]\n",
      "Mean cv score :  0.6037170541056691\n",
      "2020/12/01 22:39\n",
      "2020/12/01 22:43\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_CMNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(MultinomialNB(alpha = 0.05), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                  'vect__max_df': (0.4, 0.5),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_CMNB_0\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_CMNB_1\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_CMNB_2\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_CMNB_3\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_CMNB_4\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_CMNB_0\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_CMNB_1\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_CMNB_2\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_CMNB_3\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_CMNB_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 22:43\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   21.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   21.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   20.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.6292165710596017, 0.6394984741232733, 0.646819786619428, 0.6312645279907801, 0.6562403089836737]\n",
      "Mean cv score :  0.6406079337553514\n",
      "2020/12/01 22:43\n",
      "2020/12/01 22:47\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_CBNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(BernoulliNB(alpha = 0.02), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                  'vect__max_df': (0.03, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_CBNB_0\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_CBNB_1\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_CBNB_2\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_CBNB_3\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_CBNB_4\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_CBNB_0\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_CBNB_1\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_CBNB_2\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_CBNB_3\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_CBNB_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 22:47\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   18.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   18.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   19.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   19.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   17.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   17.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   18.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   18.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   17.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:   17.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.6026105354437366, 0.6178484475316551, 0.6170057605498341, 0.601472768549464, 0.6213367185277744]\n",
      "Mean cv score :  0.6120548461204928\n",
      "2020/12/01 22:47\n",
      "2020/12/01 22:51\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_CH_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(SGDClassifier(loss='modified_huber', alpha=0.00001, max_iter=10000, tol=1e-4), method='sigmoid')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_CH_0\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_CH_1\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_CH_2\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_CH_3\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_CH_4\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_CH_0\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_CH_1\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_CH_2\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_CH_3\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_CH_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 22:51\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.2min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.1min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.7min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.7min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.7min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  2.6min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.5620624641494352, 0.5857273048883577, 0.5885432314650478, 0.5693716851561413, 0.5916510341517979]\n",
      "Mean cv score :  0.579471143962156\n",
      "2020/12/01 22:51\n",
      "2020/12/01 23:22\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_L_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', LogisticRegression(C=50, max_iter=200)),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_L_0\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_L_1\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_L_2\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_L_3\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_L_4\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_L_0\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_L_1\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_L_2\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_L_3\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_L_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer - word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:22\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   15.7s remaining:   47.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.024\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   18.7s remaining:   56.2s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.024\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   10.0s remaining:   30.1s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   10.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.031\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   11.0s remaining:   33.3s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.024\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   11.2s remaining:   33.9s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   11.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tclf__alpha: 0.024\n",
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.25\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.5776704326928397, 0.5804705854660563, 0.6017163249986536, 0.5748083523087922, 0.5919857145779784]\n",
      "Mean cv score :  0.5853302820088641\n",
      "2020/12/01 23:22\n",
      "2020/12/01 23:24\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_MNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                  'vect__max_df': (0.25, 0.3),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "                  'clf__alpha': [0.024, 0.031],\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_MNB_0\"] = pred_train[ : , 0]\n",
    "train[\"count_MNB_1\"] = pred_train[ : , 1]\n",
    "train[\"count_MNB_2\"] = pred_train[ : , 2]\n",
    "train[\"count_MNB_3\"] = pred_train[ : , 3]\n",
    "train[\"count_MNB_4\"] = pred_train[ : , 4]\n",
    "test[\"count_MNB_0\"] = pred_full_test[ : , 0]\n",
    "test[\"count_MNB_1\"] = pred_full_test[ : , 1]\n",
    "test[\"count_MNB_2\"] = pred_full_test[ : , 2]\n",
    "test[\"count_MNB_3\"] = pred_full_test[ : , 3]\n",
    "test[\"count_MNB_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:24\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    9.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    9.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   11.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   11.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.4\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.5721619114226169, 0.5751870347960057, 0.5952297376162479, 0.5675133432744751, 0.5877951662222627]\n",
      "Mean cv score :  0.5795774386663217\n",
      "2020/12/01 23:24\n",
      "2020/12/01 23:26\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_CMNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(MultinomialNB(alpha = 0.05), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                  'vect__max_df': (0.4, 0.5),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_CMNB_0\"] = pred_train[ : , 0]\n",
    "train[\"count_CMNB_1\"] = pred_train[ : , 1]\n",
    "train[\"count_CMNB_2\"] = pred_train[ : , 2]\n",
    "train[\"count_CMNB_3\"] = pred_train[ : , 3]\n",
    "train[\"count_CMNB_4\"] = pred_train[ : , 4]\n",
    "test[\"count_CMNB_0\"] = pred_full_test[ : , 0]\n",
    "test[\"count_CMNB_1\"] = pred_full_test[ : , 1]\n",
    "test[\"count_CMNB_2\"] = pred_full_test[ : , 2]\n",
    "test[\"count_CMNB_3\"] = pred_full_test[ : , 3]\n",
    "test[\"count_CMNB_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:26\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    8.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    8.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    9.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   10.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   10.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   11.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__max_df: 0.03\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.6292165710596003, 0.6394984741232734, 0.6468197866192531, 0.6312645279907797, 0.6562403089836758]\n",
      "Mean cv score :  0.6406079337553165\n",
      "2020/12/01 23:26\n",
      "2020/12/01 23:28\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_CBNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(BernoulliNB(alpha = 0.02), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "                  'vect__max_df': (0.03, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_CBNB_0\"] = pred_train[ : , 0]\n",
    "train[\"count_CBNB_1\"] = pred_train[ : , 1]\n",
    "train[\"count_CBNB_2\"] = pred_train[ : , 2]\n",
    "train[\"count_CBNB_3\"] = pred_train[ : , 3]\n",
    "train[\"count_CBNB_4\"] = pred_train[ : , 4]\n",
    "test[\"count_CBNB_0\"] = pred_full_test[ : , 0]\n",
    "test[\"count_CBNB_1\"] = pred_full_test[ : , 1]\n",
    "test[\"count_CBNB_2\"] = pred_full_test[ : , 2]\n",
    "test[\"count_CBNB_3\"] = pred_full_test[ : , 3]\n",
    "test[\"count_CBNB_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:28\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    8.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    9.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    9.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.6122273500581314, 0.6310874332279297, 0.6303188097453891, 0.6110604158565444, 0.6305159249029815]\n",
      "Mean cv score :  0.6230419867581952\n",
      "2020/12/01 23:28\n",
      "2020/12/01 23:30\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_CH_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(SGDClassifier(loss='modified_huber', alpha=0.00001, max_iter=10000, tol=1e-4), method='sigmoid')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_CH_0\"] = pred_train[ : , 0]\n",
    "train[\"count_CH_1\"] = pred_train[ : , 1]\n",
    "train[\"count_CH_2\"] = pred_train[ : , 2]\n",
    "train[\"count_CH_3\"] = pred_train[ : , 3]\n",
    "train[\"count_CH_4\"] = pred_train[ : , 4]\n",
    "test[\"count_CH_0\"] = pred_full_test[ : , 0]\n",
    "test[\"count_CH_1\"] = pred_full_test[ : , 1]\n",
    "test[\"count_CH_2\"] = pred_full_test[ : , 2]\n",
    "test[\"count_CH_3\"] = pred_full_test[ : , 3]\n",
    "test[\"count_CH_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:30\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   2 | elapsed:  1.3min finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'word'\n",
      "\tvect__ngram_range: (1, 2)\n",
      "cv score :  [0.59456263122513, 0.6247646427582598, 0.6199121419343707, 0.5983970572232508, 0.6207081495507819]\n",
      "Mean cv score :  0.6116689245383586\n",
      "2020/12/01 23:30\n",
      "2020/12/01 23:46\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_L_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', LogisticRegression(C=50, max_iter=200)),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['word'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_L_0\"] = pred_train[ : , 0]\n",
    "train[\"count_L_1\"] = pred_train[ : , 1]\n",
    "train[\"count_L_2\"] = pred_train[ : , 2]\n",
    "train[\"count_L_3\"] = pred_train[ : , 3]\n",
    "train[\"count_L_4\"] = pred_train[ : , 4]\n",
    "test[\"count_L_0\"] = pred_full_test[ : , 0]\n",
    "test[\"count_L_1\"] = pred_full_test[ : , 1]\n",
    "test[\"count_L_2\"] = pred_full_test[ : , 2]\n",
    "test[\"count_L_3\"] = pred_full_test[ : , 3]\n",
    "test[\"count_L_4\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer - char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:46\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   13.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   32.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   32.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [1.0115280239076807, 1.0125400559034543, 1.0284658391939439, 1.012186660775046, 1.032666145731224]\n",
      "Mean cv score :  1.01947734510227\n",
      "2020/12/01 23:46\n",
      "2020/12/01 23:51\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_MNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.25, 0.3),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': [0.024, 0.031],\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_MNB_0_char\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_MNB_1_char\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_MNB_2_char\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_MNB_3_char\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_MNB_4_char\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_MNB_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_MNB_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_MNB_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_MNB_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_MNB_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:51\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   28.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   28.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   25.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   25.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   25.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   25.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   26.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   26.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   26.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   26.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [0.8708013456746512, 0.8832552137613162, 0.8938444246641268, 0.8692223806167206, 0.8929140616467663]\n",
      "Mean cv score :  0.8820074852727162\n",
      "2020/12/01 23:51\n",
      "2020/12/01 23:56\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_CMNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(MultinomialNB(alpha = 0.05), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.4, 0.5),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_CMNB_0_char\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_CMNB_1_char\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_CMNB_2_char\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_CMNB_3_char\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_CMNB_4_char\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_CMNB_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_CMNB_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_CMNB_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_CMNB_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_CMNB_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/01 23:56\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   27.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   27.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   23.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   23.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   24.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   24.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [1.2502839254949032, 1.242559166405652, 1.2661564218326058, 1.2522426310801658, 1.2723725930825402]\n",
      "Mean cv score :  1.2567229475791735\n",
      "2020/12/01 23:56\n",
      "2020/12/02 00:00\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_CBNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(BernoulliNB(alpha = 0.02), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.03, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_CBNB_0_char\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_CBNB_1_char\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_CBNB_2_char\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_CBNB_3_char\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_CBNB_4_char\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_CBNB_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_CBNB_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_CBNB_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_CBNB_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_CBNB_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:00\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [0.7518715154701759, 0.7696286784047797, 0.7732840873435437, 0.7469738449370563, 0.7654980656858875]\n",
      "Mean cv score :  0.7614512383682887\n",
      "2020/12/02 00:00\n",
      "2020/12/02 00:14\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_CH_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(SGDClassifier(loss='modified_huber', alpha=0.00001, max_iter=10000, tol=1e-4), method='sigmoid')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_CH_0_char\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_CH_1_char\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_CH_2_char\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_CH_3_char\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_CH_4_char\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_CH_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_CH_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_CH_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_CH_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_CH_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:14\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   42.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   42.0s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   36.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   36.1s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   36.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   36.7s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   38.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   38.2s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   37.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   37.9s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [0.8095727079575089, 0.8458538955991773, 0.8720832585088008, 0.7842694820340493, 0.8464996491968897]\n",
      "Mean cv score :  0.8316557986592852\n",
      "2020/12/02 00:14\n",
      "2020/12/02 00:23\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# tfidf_L_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', TfidfVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', LogisticRegression(C=50, max_iter=200)),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"tfidf_L_0_char\"] = pred_train[ : , 0]\n",
    "train[\"tfidf_L_1_char\"] = pred_train[ : , 1]\n",
    "train[\"tfidf_L_2_char\"] = pred_train[ : , 2]\n",
    "train[\"tfidf_L_3_char\"] = pred_train[ : , 3]\n",
    "train[\"tfidf_L_4_char\"] = pred_train[ : , 4]\n",
    "test[\"tfidf_L_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"tfidf_L_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"tfidf_L_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"tfidf_L_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"tfidf_L_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer - char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:23\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   14.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   14.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   14.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   17.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [1.2025769972789655, 1.196017341161219, 1.2158048511371249, 1.204632802204555, 1.215416507101536]\n",
      "Mean cv score :  1.20688969977668\n",
      "2020/12/02 00:23\n",
      "2020/12/02 00:26\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_MNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', MultinomialNB()),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.25, 0.3),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': [0.024, 0.031],\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_MNB_0_char\"] = pred_train[ : , 0]\n",
    "train[\"count_MNB_1_char\"] = pred_train[ : , 1]\n",
    "train[\"count_MNB_2_char\"] = pred_train[ : , 2]\n",
    "train[\"count_MNB_3_char\"] = pred_train[ : , 3]\n",
    "train[\"count_MNB_4_char\"] = pred_train[ : , 4]\n",
    "test[\"count_MNB_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"count_MNB_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"count_MNB_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"count_MNB_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"count_MNB_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:26\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   20.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   20.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   19.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.5s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [0.899373766481415, 0.9028902679565609, 0.9204983140389096, 0.8936078919693751, 0.9246590782329285]\n",
      "Mean cv score :  0.9082058637358378\n",
      "2020/12/02 00:26\n",
      "2020/12/02 00:30\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_CMNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(MultinomialNB(alpha = 0.05), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.4, 0.5),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_CMNB_0_char\"] = pred_train[ : , 0]\n",
    "train[\"count_CMNB_1_char\"] = pred_train[ : , 1]\n",
    "train[\"count_CMNB_2_char\"] = pred_train[ : , 2]\n",
    "train[\"count_CMNB_3_char\"] = pred_train[ : , 3]\n",
    "train[\"count_CMNB_4_char\"] = pred_train[ : , 4]\n",
    "test[\"count_CMNB_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"count_CMNB_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"count_CMNB_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"count_CMNB_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"count_CMNB_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:30\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   21.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   21.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   16.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.8s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   15.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   20.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   20.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [1.2502839254949023, 1.2425591664056512, 1.2661564218326065, 1.2522426310801653, 1.2723725930825422]\n",
      "Mean cv score :  1.2567229475791735\n",
      "2020/12/02 00:30\n",
      "2020/12/02 00:34\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_CBNB_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(BernoulliNB(alpha = 0.02), method='isotonic')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.03, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_CBNB_0_char\"] = pred_train[ : , 0]\n",
    "train[\"count_CBNB_1_char\"] = pred_train[ : , 1]\n",
    "train[\"count_CBNB_2_char\"] = pred_train[ : , 2]\n",
    "train[\"count_CBNB_3_char\"] = pred_train[ : , 3]\n",
    "train[\"count_CBNB_4_char\"] = pred_train[ : , 4]\n",
    "test[\"count_CBNB_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"count_CBNB_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"count_CBNB_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"count_CBNB_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"count_CBNB_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:34\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   59.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   59.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   58.3s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   58.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.0min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   57.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   57.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   58.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   58.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [0.7693733031820273, 0.7891490830442921, 0.794005424334621, 0.7662423414060131, 0.7873459511333336]\n",
      "Mean cv score :  0.7812232206200573\n",
      "2020/12/02 00:34\n",
      "2020/12/02 00:46\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_CH_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', CalibratedClassifierCV(SGDClassifier(loss='modified_huber', alpha=0.00001, max_iter=10000, tol=1e-4), method='sigmoid')),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_CH_0_char\"] = pred_train[ : , 0]\n",
    "train[\"count_CH_1_char\"] = pred_train[ : , 1]\n",
    "train[\"count_CH_2_char\"] = pred_train[ : , 2]\n",
    "train[\"count_CH_3_char\"] = pred_train[ : , 3]\n",
    "train[\"count_CH_4_char\"] = pred_train[ : , 4]\n",
    "test[\"count_CH_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"count_CH_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"count_CH_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"count_CH_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"count_CH_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:46\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   38.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   38.4s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   37.7s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   37.7s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   38.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   38.9s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   39.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   39.1s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "Fitting 2 folds for each of 2 candidates, totalling 4 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   34.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   4 out of   4 | elapsed:   34.9s finished\n",
      "C:\\Users\\id272\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tvect__analyzer: 'char'\n",
      "\tvect__ngram_range: (1, 3)\n",
      "cv score :  [0.7988854018201208, 0.8270402219678563, 0.8227781506143519, 0.812051650233377, 0.8311840983155193]\n",
      "Mean cv score :  0.8183879045902451\n",
      "2020/12/02 00:46\n",
      "2020/12/02 00:55\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# count_L_\n",
    "cv_scores = []\n",
    "pred_full_test = 0\n",
    "pred_train = np.zeros([train.shape[0], 5])\n",
    "\n",
    "kf = model_selection.KFold(n_splits = 5, shuffle = True, random_state = 32143233)\n",
    "for dev_index, val_index in kf.split(train):\n",
    "    dev_X, val_X = X_train[dev_index], X_train[val_index]\n",
    "    dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "\n",
    "    classifier = Pipeline([('vect', CountVectorizer(lowercase=False)),\n",
    "                          ('tfidf', TfidfTransformer()),\n",
    "                          ('clf', LogisticRegression(C=50, max_iter=200)),\n",
    "    ])\n",
    "    parameters = {'vect__ngram_range': [(1, 2), (1, 3)],\n",
    "#                   'vect__max_df': (0.3, 0.4),\n",
    "#                   'vect__min_df': [1],\n",
    "                  'vect__analyzer' : ['char'],\n",
    "#                   'clf__alpha': (0.016, 0.018),\n",
    "    }\n",
    "    gs_clf = GridSearchCV(classifier, parameters, n_jobs=-1, verbose=1, cv=2)\n",
    "    gs_clf.fit(dev_X, dev_y)\n",
    "    best_parameters = gs_clf.best_estimator_.get_params()\n",
    "    for param_name in sorted(parameters.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "    \n",
    "    pred_test_y = gs_clf.predict_proba(val_X)\n",
    "    pred_test_y2 = gs_clf.predict_proba(X_test)\n",
    "    pred_full_test = pred_full_test + pred_test_y2\n",
    "    pred_train[val_index, : ] = pred_test_y\n",
    "    cv_scores.append(metrics.log_loss(val_y, pred_test_y))\n",
    "print(\"cv score : \", cv_scores)\n",
    "print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "pred_full_test = pred_full_test / 5\n",
    "\n",
    "train[\"count_L_0_char\"] = pred_train[ : , 0]\n",
    "train[\"count_L_1_char\"] = pred_train[ : , 1]\n",
    "train[\"count_L_2_char\"] = pred_train[ : , 2]\n",
    "train[\"count_L_3_char\"] = pred_train[ : , 3]\n",
    "train[\"count_L_4_char\"] = pred_train[ : , 4]\n",
    "test[\"count_L_0_char\"] = pred_full_test[ : , 0]\n",
    "test[\"count_L_1_char\"] = pred_full_test[ : , 1]\n",
    "test[\"count_L_2_char\"] = pred_full_test[ : , 2]\n",
    "test[\"count_L_3_char\"] = pred_full_test[ : , 3]\n",
    "test[\"count_L_4_char\"] = pred_full_test[ : , 4]    \n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020/12/02 00:55\n",
      "[0]\ttrain-mlogloss:1.42802\ttest-mlogloss:1.42744\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.46950\ttest-mlogloss:0.48200\n",
      "[40]\ttrain-mlogloss:0.35241\ttest-mlogloss:0.38115\n",
      "[60]\ttrain-mlogloss:0.31889\ttest-mlogloss:0.36436\n",
      "[80]\ttrain-mlogloss:0.29810\ttest-mlogloss:0.35896\n",
      "[100]\ttrain-mlogloss:0.27932\ttest-mlogloss:0.35714\n",
      "[120]\ttrain-mlogloss:0.26241\ttest-mlogloss:0.35603\n",
      "[140]\ttrain-mlogloss:0.24639\ttest-mlogloss:0.35555\n",
      "[160]\ttrain-mlogloss:0.23160\ttest-mlogloss:0.35489\n",
      "[180]\ttrain-mlogloss:0.21767\ttest-mlogloss:0.35511\n",
      "[200]\ttrain-mlogloss:0.20495\ttest-mlogloss:0.35518\n",
      "Stopping. Best iteration:\n",
      "[157]\ttrain-mlogloss:0.23374\ttest-mlogloss:0.35475\n",
      "\n",
      "[0]\ttrain-mlogloss:1.42771\ttest-mlogloss:1.43243\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.46468\ttest-mlogloss:0.50274\n",
      "[40]\ttrain-mlogloss:0.34701\ttest-mlogloss:0.40293\n",
      "[60]\ttrain-mlogloss:0.31351\ttest-mlogloss:0.38493\n",
      "[80]\ttrain-mlogloss:0.29222\ttest-mlogloss:0.37913\n",
      "[100]\ttrain-mlogloss:0.27349\ttest-mlogloss:0.37665\n",
      "[120]\ttrain-mlogloss:0.25578\ttest-mlogloss:0.37561\n",
      "[140]\ttrain-mlogloss:0.24028\ttest-mlogloss:0.37550\n",
      "[160]\ttrain-mlogloss:0.22603\ttest-mlogloss:0.37583\n",
      "Stopping. Best iteration:\n",
      "[125]\ttrain-mlogloss:0.25194\ttest-mlogloss:0.37532\n",
      "\n",
      "[0]\ttrain-mlogloss:1.42794\ttest-mlogloss:1.43131\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.46501\ttest-mlogloss:0.49840\n",
      "[40]\ttrain-mlogloss:0.34731\ttest-mlogloss:0.39957\n",
      "[60]\ttrain-mlogloss:0.31451\ttest-mlogloss:0.38236\n",
      "[80]\ttrain-mlogloss:0.29321\ttest-mlogloss:0.37701\n",
      "[100]\ttrain-mlogloss:0.27453\ttest-mlogloss:0.37552\n",
      "[120]\ttrain-mlogloss:0.25682\ttest-mlogloss:0.37425\n",
      "[140]\ttrain-mlogloss:0.24130\ttest-mlogloss:0.37389\n",
      "[160]\ttrain-mlogloss:0.22645\ttest-mlogloss:0.37377\n",
      "[180]\ttrain-mlogloss:0.21352\ttest-mlogloss:0.37401\n",
      "[200]\ttrain-mlogloss:0.20071\ttest-mlogloss:0.37442\n",
      "Stopping. Best iteration:\n",
      "[162]\ttrain-mlogloss:0.22524\ttest-mlogloss:0.37370\n",
      "\n",
      "[0]\ttrain-mlogloss:1.42823\ttest-mlogloss:1.42998\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.46862\ttest-mlogloss:0.48628\n",
      "[40]\ttrain-mlogloss:0.35167\ttest-mlogloss:0.38429\n",
      "[60]\ttrain-mlogloss:0.31838\ttest-mlogloss:0.36629\n",
      "[80]\ttrain-mlogloss:0.29718\ttest-mlogloss:0.36089\n",
      "[100]\ttrain-mlogloss:0.27884\ttest-mlogloss:0.35922\n",
      "[120]\ttrain-mlogloss:0.26208\ttest-mlogloss:0.35852\n",
      "[140]\ttrain-mlogloss:0.24641\ttest-mlogloss:0.35804\n",
      "[160]\ttrain-mlogloss:0.23116\ttest-mlogloss:0.35762\n",
      "[180]\ttrain-mlogloss:0.21766\ttest-mlogloss:0.35790\n",
      "[200]\ttrain-mlogloss:0.20539\ttest-mlogloss:0.35799\n",
      "Stopping. Best iteration:\n",
      "[159]\ttrain-mlogloss:0.23180\ttest-mlogloss:0.35749\n",
      "\n",
      "[0]\ttrain-mlogloss:1.42969\ttest-mlogloss:1.43147\n",
      "Multiple eval metrics have been passed: 'test-mlogloss' will be used for early stopping.\n",
      "\n",
      "Will train until test-mlogloss hasn't improved in 50 rounds.\n",
      "[20]\ttrain-mlogloss:0.46509\ttest-mlogloss:0.49593\n",
      "[40]\ttrain-mlogloss:0.34831\ttest-mlogloss:0.39917\n",
      "[60]\ttrain-mlogloss:0.31493\ttest-mlogloss:0.38254\n",
      "[80]\ttrain-mlogloss:0.29265\ttest-mlogloss:0.37696\n",
      "[100]\ttrain-mlogloss:0.27457\ttest-mlogloss:0.37433\n",
      "[120]\ttrain-mlogloss:0.25785\ttest-mlogloss:0.37311\n",
      "[140]\ttrain-mlogloss:0.24239\ttest-mlogloss:0.37257\n",
      "[160]\ttrain-mlogloss:0.22793\ttest-mlogloss:0.37269\n",
      "[180]\ttrain-mlogloss:0.21490\ttest-mlogloss:0.37320\n",
      "Stopping. Best iteration:\n",
      "[147]\ttrain-mlogloss:0.23706\ttest-mlogloss:0.37240\n",
      "\n",
      "cv score :  [0.35475335016523574, 0.3753240263740126, 0.37369690713018755, 0.3574915867155482, 0.37240149473934475]\n",
      "Mean cv score :  0.3667334730248658\n",
      "2020/12/02 00:55\n",
      "2020/12/02 01:08\n"
     ]
    }
   ],
   "source": [
    "start = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "# Final Model\n",
    "# XGBoost\n",
    "def runXGB(train_X, train_y, test_X, test_y=None, test_X2=None, seed_val=0, child=1, colsample=0.3):\n",
    "    param = {}\n",
    "    param['objective'] = 'multi:softprob'\n",
    "    param['eta'] = 0.1\n",
    "    param['max_depth'] = 5\n",
    "#     param['silent'] = 1\n",
    "    param['num_class'] = 5\n",
    "    param['eval_metric'] = \"mlogloss\"\n",
    "    param['min_child_weight'] = child\n",
    "    param['subsample'] = 0.8\n",
    "    param['colsample_bytree'] = colsample\n",
    "    param['seed'] = seed_val\n",
    "    num_rounds = 2000\n",
    "\n",
    "    plst = list(param.items())\n",
    "    xgtrain = xgb.DMatrix(train_X, label=train_y)\n",
    "\n",
    "    if test_y is not None:\n",
    "        xgtest = xgb.DMatrix(test_X, label=test_y)\n",
    "        watchlist = [ (xgtrain,'train'), (xgtest, 'test') ]\n",
    "        model = xgb.train(plst, xgtrain, num_rounds, watchlist, early_stopping_rounds=50, verbose_eval=20)\n",
    "    else:\n",
    "        xgtest = xgb.DMatrix(test_X)\n",
    "        model = xgb.train(plst, xgtrain, num_rounds)\n",
    "\n",
    "    pred_test_y = model.predict(xgtest, ntree_limit = model.best_ntree_limit)\n",
    "    if test_X2 is not None:\n",
    "        xgtest2 = xgb.DMatrix(test_X2)\n",
    "        pred_test_y2 = model.predict(xgtest2, ntree_limit = model.best_ntree_limit)\n",
    "    return pred_test_y, pred_test_y2, model\n",
    "\n",
    "def do(train, test, Y_train):\n",
    "    drop_columns=['index', \"text\"]\n",
    "    x_train = train.drop(drop_columns+['author'],axis=1)\n",
    "    x_test = test.drop(drop_columns,axis=1)\n",
    "    y_train = Y_train\n",
    "    \n",
    "    kf = model_selection.KFold(n_splits=5, shuffle=True, random_state=32143233)\n",
    "    cv_scores = []\n",
    "    pred_full_test = 0\n",
    "    pred_train = np.zeros([x_train.shape[0], 5])\n",
    "    for dev_index, val_index in kf.split(x_train):\n",
    "        dev_X, val_X = x_train.loc[dev_index], x_train.loc[val_index]\n",
    "        dev_y, val_y = y_train[dev_index], y_train[val_index]\n",
    "        pred_val_y, pred_test_y, model = runXGB(dev_X, dev_y, val_X, val_y, x_test, seed_val=0, colsample=0.7)\n",
    "        pred_full_test = pred_full_test + pred_test_y\n",
    "        pred_train[val_index,:] = pred_val_y\n",
    "        cv_scores.append(metrics.log_loss(val_y, pred_val_y))\n",
    "    print(\"cv score : \", cv_scores)\n",
    "    print(\"Mean cv score : \", np.mean(cv_scores))\n",
    "    return pred_full_test/5\n",
    "result = do(train, test, Y_train)\n",
    "\n",
    "end = time.localtime()\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (start.tm_year, start.tm_mon, start.tm_mday, start.tm_hour, start.tm_min))\n",
    "print(\"%04d/%02d/%02d %02d:%02d\" % (end.tm_year, end.tm_mon, end.tm_mday, end.tm_hour, end.tm_min))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # cv score :  [0.3641794996825376, 0.3822802325154725, 0.37811282920527145, 0.3630294105994838, 0.3801573158655308]\n",
    "# # Mean cv score :  0.3735518575736593\n",
    "\n",
    "# cv score :  [0.35475335016523574, 0.3753240263740126, 0.37369690713018755, 0.3574915867155482, 0.37240149473934475]\n",
    "# Mean cv score :  0.3667334730248658"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv('open/new_train.csv', index=False)\n",
    "test.to_csv('open/new_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.005643</td>\n",
       "      <td>0.569645</td>\n",
       "      <td>0.409466</td>\n",
       "      <td>0.013175</td>\n",
       "      <td>0.002072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.002242</td>\n",
       "      <td>0.994056</td>\n",
       "      <td>0.001584</td>\n",
       "      <td>0.000525</td>\n",
       "      <td>0.001594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.998047</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>0.001000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.000277</td>\n",
       "      <td>0.004009</td>\n",
       "      <td>0.994443</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.001020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.987226</td>\n",
       "      <td>0.004116</td>\n",
       "      <td>0.003481</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.000798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19612</th>\n",
       "      <td>19612</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.999471</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19613</th>\n",
       "      <td>19613</td>\n",
       "      <td>0.000428</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.998547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19614</th>\n",
       "      <td>19614</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.999104</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19615</th>\n",
       "      <td>19615</td>\n",
       "      <td>0.000282</td>\n",
       "      <td>0.998725</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.000110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19616</th>\n",
       "      <td>19616</td>\n",
       "      <td>0.985365</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.001043</td>\n",
       "      <td>0.000644</td>\n",
       "      <td>0.012319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19617 rows  6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index         0         1         2         3         4\n",
       "0          0  0.005643  0.569645  0.409466  0.013175  0.002072\n",
       "1          1  0.002242  0.994056  0.001584  0.000525  0.001594\n",
       "2          2  0.998047  0.000647  0.000165  0.000141  0.001000\n",
       "3          3  0.000277  0.004009  0.994443  0.000250  0.001020\n",
       "4          4  0.987226  0.004116  0.003481  0.004380  0.000798\n",
       "...      ...       ...       ...       ...       ...       ...\n",
       "19612  19612  0.000185  0.999471  0.000119  0.000154  0.000070\n",
       "19613  19613  0.000428  0.000189  0.000704  0.000133  0.998547\n",
       "19614  19614  0.000415  0.999104  0.000151  0.000237  0.000093\n",
       "19615  19615  0.000282  0.998725  0.000415  0.000467  0.000110\n",
       "19616  19616  0.985365  0.000630  0.001043  0.000644  0.012319\n",
       "\n",
       "[19617 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_submission=pd.read_csv('open/sample_submission.csv', encoding='utf-8')\n",
    "sample_submission[['0', '1', '2', '3', '4']] = result\n",
    "sample_submission.to_csv(\"kg_8_1201.csv\", index=False)\n",
    "sample_submission"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
